{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b510ab6f-fe99-4873-90e6-b1d11fa284f9",
   "metadata": {},
   "source": [
    "## 1 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fd9b9-d28d-4deb-8889-085883134012",
   "metadata": {},
   "source": [
    "What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55795f9-6de5-4e11-ad51-63f57b7aa0a2",
   "metadata": {},
   "source": [
    "Ans :Web scraping is the process of extracting data from websites using automated tools or software. \n",
    "\n",
    "Web scraping is used for:\n",
    "\n",
    "Data gathering: Web scraping is used to collect large amounts of data quickly and efficiently. This can include product information, customer reviews, pricing data, or any other information that is publicly available on the web.\n",
    "\n",
    "Market research: Companies use web scraping to monitor competitors, track industry trends, and identify new business opportunities.\n",
    "\n",
    "Data analysis: Researchers and analysts use web scraping to collect data for analysis and visualization. This can include social media data, news articles, or any other data that is available on the web.\n",
    "\n",
    "Three areas where web scraping is commonly used include:\n",
    "\n",
    "E-commerce: Web scraping is used in the e-commerce industry to collect product information, pricing data, and customer reviews from online retailers.\n",
    "\n",
    "Market research: Web scraping is used in market research to gather data on competitors, track industry trends, and identify new business opportunities.\n",
    "\n",
    "Social media analysis: Web scraping is used to collect social media data from platforms such as Twitter, Facebook, and Instagram for sentiment analysis, brand monitoring, and market research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba1058-6aa5-4007-b5c1-48452200e884",
   "metadata": {},
   "source": [
    " ## 2 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd9e66-e392-4b9e-b557-b4160c864925",
   "metadata": {},
   "source": [
    "What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6b98b-1028-4a3c-be95-ea344928ddd7",
   "metadata": {},
   "source": [
    "Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e1c13-0e49-4036-8fd1-56381d706219",
   "metadata": {},
   "source": [
    "1.Manual scraping: This involves manually copying and pasting information from web pages into a spreadsheet or database. This is a time-consuming and labor-intensive process, but it can be useful for small-scale scraping projects.\n",
    "\n",
    "2.Web scraping software: There are many software tools available for web scraping, such as BeautifulSoup, Scrapy, and Selenium. These tools can automate the process of web scraping by identifying the relevant data on a website and extracting it into a structured format.\n",
    "\n",
    "3.Application programming interfaces (APIs): Many websites provide APIs that allow developers to access their data programmatically. This can be a more efficient and reliable way to access data, as it avoids the need for web scraping.\n",
    "\n",
    "4.Data extraction services: There are companies that offer data extraction services, where they use their own web scraping tools and techniques to gather data from websites on behalf of their clients. This can be a good option for businesses that need to collect large amounts of data quickly and efficiently.\n",
    "\n",
    "5.Browser extensions: Some browser extensions, such as Data Miner and Web Scraper, allow users to scrape data from websites without requiring any coding knowledge. These extensions can be useful for small-scale scraping projects or for users who are not familiar with programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef9332-0523-4fd6-9b28-e5a0696852bf",
   "metadata": {},
   "source": [
    "## 3 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5de8f-eade-48fc-8d16-1720cf5ec009",
   "metadata": {},
   "source": [
    "What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb564d-b798-40db-9748-cb0c07da076b",
   "metadata": {},
   "source": [
    "Ans :Beautiful Soup is a Python library that is used for web scraping purposes. It provides a set of functions and methods that allow developers to extract data from HTML and XML documents.\n",
    "\n",
    "Beautiful Soup is used because it simplifies the process of parsing and navigating HTML and XML documents, which can be complex and time-consuming. It provides a convenient way to extract specific data from web pages by allowing developers to search for and extract elements based on their tag names, attributes, and text content.\n",
    "\n",
    "Here are some reasons why Beautiful Soup is a popular tool for web scraping:\n",
    "\n",
    "Easy to use: Beautiful Soup is a user-friendly library that can be used by developers of all skill levels. It provides a simple and intuitive interface for parsing and navigating HTML and XML documents.\n",
    "\n",
    "Flexible: Beautiful Soup can handle poorly formatted HTML and XML documents, which can be a common problem when scraping data from the web. It is also able to work with different parsers, giving developers more flexibility in how they extract data.\n",
    "\n",
    "Robust: Beautiful Soup is a stable and reliable library that is actively maintained by its developers. It has been used by many developers for a wide range of web scraping projects and has a large community of users who contribute to its development.\n",
    "\n",
    "Python integration: Beautiful Soup is a Python library, which makes it easy to integrate with other Python libraries and tools. This allows developers to create powerful web scraping scripts using a combination of tools and libraries that work seamlessly together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d953f1-2a0e-4ce0-b88e-281b6dd6194d",
   "metadata": {},
   "source": [
    "## 4 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0678e52-202f-4a14-bf97-c69ecfa85a6b",
   "metadata": {},
   "source": [
    "Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c422b6f-a131-4307-8a54-ef9595c5f162",
   "metadata": {},
   "source": [
    "Ans: Flask is a lightweight and flexible web application framework that is used in web scraping projects for:\n",
    "\n",
    "Web interface: Flask can be used to create a web interface that allows users to interact with the web scraping application. This can include entering search queries, specifying search parameters, and viewing the results of the web scraping process.\n",
    "\n",
    "Integration with Beautiful Soup: Flask can be integrated with Beautiful Soup to create a powerful web scraping tool that is both easy to use and flexible.\n",
    "\n",
    "Customization: Flask provides a high degree of customization, allowing developers to create web scraping applications that meet their specific requirements. \n",
    "\n",
    "Scalability: Flask is a lightweight framework that is easy to scale. This means that it can be used to create web scraping applications that are able to handle large amounts of data and traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f9f09-0106-4f0e-8f8e-0046183047fd",
   "metadata": {},
   "source": [
    "## 5 Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cfc45-9355-412f-8b96-2bb3fbdee6d9",
   "metadata": {},
   "source": [
    "Write the names of AWS services used in this project. Also, explain the use of each service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa7a51-2666-4a61-bf25-fa185283c71a",
   "metadata": {},
   "source": [
    "Ans: Aws services used is  : 1.codpipeline 2.elastic beanstalk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfcf87c-f6d3-4e4c-ad6c-eba52b2ade3d",
   "metadata": {},
   "source": [
    "AWS Codpipeline: AWS CodePipeline is a fully managed continuous delivery service that helps developers automate their software release process. It allows developers to build, test, and deploy their code changes quickly and reliably. \n",
    "The main features of AWS CodePipeline include:\n",
    "\n",
    "Pipeline visualizations and dashboards for managing the release process\n",
    "Integration with other AWS services for building, testing, and deploying applications\n",
    "Automated change detection and rollback capabilities\n",
    "Customizable stages and actions for a tailored release process\n",
    "Integration with third-party tools and services via APIs\n",
    "\n",
    "AWS Elastic Beanstalk: AWS Elastic Beanstalk is a fully managed service that allows developers to quickly deploy and manage web applications in the AWS Cloud. It supports multiple programming languages, such as Java, Python, Node.js, and Ruby, and provides a flexible environment for running web applications.\n",
    "The main features of AWS Elastic Beanstalk include:\n",
    "\n",
    "Easy deployment and management of web applications\n",
    "Scalability and availability features to ensure high performance\n",
    "Integration with other AWS services for enhanced functionality\n",
    "Customizable application environments for a tailored deployment process\n",
    "Support for multiple programming languages and frameworks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
